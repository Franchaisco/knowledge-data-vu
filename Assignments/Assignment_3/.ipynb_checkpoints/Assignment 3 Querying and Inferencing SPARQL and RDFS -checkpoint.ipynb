{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge and Data: Practical Assignment 3 \n",
    "## RDF Data, RDFS knowledge and inferencing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR NAME: Francis Babila Niba\n",
    "\n",
    "YOUR VUNetID: fba228\n",
    "\n",
    "*(If you do not provide your name and VUNetID we will not accept your submission).* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning objectives\n",
    "\n",
    "At the end of this exercise you should be able to:\n",
    "\n",
    "1. Access local an external data via SPARQL both from within a python programming environment and stand-alone with a GUI, such as [YASGUI](https://yasgui.triply.cc/), and this way integrate data from different sources  \n",
    "2. Model your own first knowledge base, in this case an RDF Schema knowledge graph\n",
    "3. Implement inference rules "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow this Notebook step-by-step. \n",
    "\n",
    "Of course, you can do the exercises in any Programming Editor of your liking. \n",
    "But you do not have to. Feel free to simply write code in the Notebook. When \n",
    "everythink is filled in and works, safe the Notebook and submit it \n",
    "as a Jupyter Notebook, i.e. with an ipynb extension. Please use as name of the \n",
    "Notebook your studentID+Assignment3.ipynb.  \n",
    "\n",
    "\n",
    "We will not evaluate the programming style of your solutions. Yet we do look whether your solutions suggests an understanding, and whether they yield the correct output.\n",
    "\n",
    "Note that all notebooks will automatically be checked for plagiarism: while similar answers can be expected, it is not allowed to directly copy the solutions from fellow students or TAs, or from the examples discussed during the lectures. Similarly, sharing your solutions with your peers is not allowed.\n",
    "\n",
    "**IMPORTANT: Submit this notebook after finishing the assignment. It is not necessary to submit the created turtle files**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you start, you need to:\n",
    "\n",
    "- **Install the *rdflib* Python package:** *pip install rdflib* (should already be installed from the previous assignment)\n",
    "- **Install the *SPARQLWrapper* Python package:** *pip install SPARQLWrapper*\n",
    "- **Install the free edition of the GraphDB Triplestore:** please follow this short [GraphDB tutorial](https://github.com/ucds-vu/knowledge-data-vu/blob/master/Tutorials/Preliminaries/tutorial-GraphDB.md). \n",
    "\n",
    "Then, add the file example-from-slides.ttl to a newly created database, say called assignment-3. \n",
    "\n",
    "**Note that you should have an active internet connection to run the code in this notebook. If, for some external reason (ie internet and/or system issues), you cannot access the SPARQL endpoint, then report this to a TA as soon as possible!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install library\n",
    "%pip install SPARQLWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: (35 points) Integrate Local and External Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can integrate SPARQL queries into your Python code by using the *RDFLib* and *SPARQLWrapper* libraries. \n",
    "\n",
    "The following code accesses the DBPedia knowledge graph using its SPARQL endpoint, and returns the result of the SPARQL query requesting all the labels asserted to Amsterdam (test it!)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code only works if you are online.\n",
    "# If, for some reason, you cannot get this to work, then please contact a TA\n",
    "\n",
    "from rdflib import Graph, RDF, RDFS, Namespace, Literal, URIRef\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "sparql.setQuery(\"\"\"\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    SELECT ?cityName\n",
    "    WHERE { \n",
    "        <http://dbpedia.org/resource/Amsterdam> rdfs:label ?cityName \n",
    "    }\n",
    "\"\"\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    print(result[\"cityName\"][\"value\"])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your convenience, we already wrote the following functions that might be useful to complete this task. \n",
    "In addition, we have loaded and printed the 'example-from-slides.ttl' dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph, RDF, Namespace, Literal, URIRef\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "\n",
    "# Loads the data from a certain file given as input in Turtle syntax into the Graph g  \n",
    "# -------------------------\n",
    "def load_graph(graph, filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        graph.parse(f, format='turtle')\n",
    "        \n",
    "\n",
    "# Prints a certain graph given as input in Turtle syntax\n",
    "# if your output shows byte string (ie, b'...') you must add '.decode()' to the print statements:\n",
    "#    print(myGraph.serialize(format='turtle').decode())\n",
    "# -------------------------\n",
    "def serialize_graph(myGraph):\n",
    "     print(myGraph.serialize(format='turtle'))\n",
    "        \n",
    "\n",
    "# Saves the Graph g in Turtle syntax to a certain file given as input\n",
    "# -------------------------\n",
    "def save_graph(myGraph, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        myGraph.serialize(filename, format='turtle')\n",
    "        \n",
    "    \n",
    "# Changes the namespace of a certain URI given as input to a DBpedia URI \n",
    "# Example: transformToDBR(\"http://example.com/kad2020/Amsterdam\") returns \"http://dbpedia.org/resource/Amsterdam\"\n",
    "# -------------------------\n",
    "def transformToDBR(uri):\n",
    "    if isinstance(uri, Literal):\n",
    "        # changes the literal to uppercase so that the object with the same name refers to an object and not the string\n",
    "        return uri.upper()\n",
    "    components = g.namespace_manager.compute_qname(uri)\n",
    "    return \"http://dbpedia.org/resource/%s\"%(components[2])\n",
    "\n",
    "# -------------------------\n",
    "\n",
    "g = Graph()\n",
    "load_graph(g, 'example-from-slides.ttl')\n",
    "serialize_graph(g)\n",
    "\n",
    "\n",
    "# Don't forget to run this cell before continuing the task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A: Write a SPARQL query that finds all the cities in the dataset\n",
    "\n",
    "As you cannot directly use class City, you will have to find those cities in the dataset (example-from-slides.ttl) using implicit information that can be deduced from the domain and ranges of the relations (e.g. things in a hasCapital relation are capitals and a capital is a city, etc.).\n",
    "\n",
    "Save all the cities returned from the SPARQL query into the empty set \"cities\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = set()\n",
    "\n",
    "cities = g.query(\"\"\"\n",
    "    PREFIX ex: <http://example.com/kad/>\n",
    "    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "    \n",
    "    SELECT DISTINCT ?city\n",
    "    WHERE {\n",
    "      ?country ?prop ?city .\n",
    "      ?prop rdfs:subPropertyOf* ex:containsCity .\n",
    "    }\n",
    "\"\"\")\n",
    "\n",
    "    \n",
    "for city in cities:\n",
    "    uri = city[0] \n",
    "    city_name = str(uri).split('/')[-1]  \n",
    "    print(city_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B: For each city, find from DBpedia its longitude & latitude, and its number of inhabitants (if available)\n",
    "\n",
    "Don't forget to adapt the namespace of the cities in your dataset when querying DBpedia, using the above function *transformToDBR(uri)*. Also note that namespaces should never use the *https* protocol.\n",
    "\n",
    "The empty graph h should only contain the triples extracted from DBpedia, but added to the URIs with the 'ex' namespace. \n",
    "An example of a triple in h is the following triple: \n",
    "       \n",
    "       ex:Amsterdam dbo:populationTotal \"872680\"^^xsd:nonNegativeInteger ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = Graph()\n",
    "\n",
    "ex = Namespace(\"http://example.com/kad/\")\n",
    "lat = URIRef(\"http://www.w3.org/2003/01/geo/wgs84_pos#lat\")\n",
    "long = URIRef(\"http://www.w3.org/2003/01/geo/wgs84_pos#long\")\n",
    "popNum = URIRef(\"http://dbpedia.org/ontology/populationTotal\")\n",
    "\n",
    "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "\n",
    "for city in cities:\n",
    "    city_uri = transformToDBR(city[0])\n",
    "    city_name = str(city[0]).split('/')[-1]\n",
    "    city_ref = ex[city_name]\n",
    "\n",
    "    sparql.setQuery(f\"\"\"\n",
    "        PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "        PREFIX geo: <http://www.w3.org/2003/01/geo/wgs84_pos#>\n",
    "        SELECT ?lat ?long ?pop\n",
    "        WHERE {{\n",
    "            <{city_uri}> geo:lat ?lat .\n",
    "            <{city_uri}> geo:long ?long .\n",
    "            OPTIONAL {{ <{city_uri}> dbo:populationTotal ?pop }}\n",
    "        }}\n",
    "    \"\"\")\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    \n",
    "    for result in results[\"results\"][\"bindings\"]:\n",
    "        h.add((city_ref, lat, Literal(result[\"lat\"][\"value\"])))\n",
    "        h.add((city_ref, long, Literal(result[\"long\"][\"value\"])))\n",
    "        \n",
    "        if \"pop\" in result:\n",
    "            h.add((city_ref, popNum, Literal(result[\"pop\"][\"value\"])))\n",
    "\n",
    "serialize_graph(h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C: Save your results\n",
    "\n",
    "- Merge the triples from example-from-slides.ttl with the information extracted from DBpedia. See the [documentation](https://rdflib.readthedocs.io/en/stable/merging.html) on how to accomplish this.\n",
    "- Save all these triples into a new file 'extended-example.ttl'. **It is not necessary to submit this file**\n",
    "- Print all triples in Turtle Syntax.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix ex: <http://example.com/kad/> .\n",
      "@prefix ns1: <http://www.w3.org/2003/01/geo/wgs84_pos#> .\n",
      "@prefix ns2: <http://dbpedia.org/ontology/> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "\n",
      "ex:Netherlands a ex:Country ;\n",
      "    ex:contains ex:Ijsselmeer ;\n",
      "    ex:containsCity ex:Rotterdam ;\n",
      "    ex:hasCapital ex:Amsterdam ;\n",
      "    ex:hasName \"The Netherlands\" ;\n",
      "    ex:neighbours ex:Belgium .\n",
      "\n",
      "ex:hasCapital rdfs:range ex:Capital ;\n",
      "    rdfs:subPropertyOf ex:containsCity .\n",
      "\n",
      "ex:neighbours rdfs:subPropertyOf ex:closeBy .\n",
      "\n",
      "ex:Amsterdam a ex:Capital ;\n",
      "    ns2:populationTotal \"907976\" ;\n",
      "    ex:closeBy ex:Germany ;\n",
      "    ns1:lat \"52.36666488647461\" ;\n",
      "    ns1:long \"4.900000095367432\" .\n",
      "\n",
      "ex:Belgium a ex:Country .\n",
      "\n",
      "ex:Berlin ns2:populationTotal \"3677472\" ;\n",
      "    ns1:lat \"52.52000045776367\" ;\n",
      "    ns1:long \"13.40499973297119\" .\n",
      "\n",
      "ex:EuropeanCountry rdfs:subClassOf ex:Country .\n",
      "\n",
      "ex:Germany a ex:EuropeanCountry ;\n",
      "    ex:hasCapital ex:Berlin .\n",
      "\n",
      "ex:Rotterdam ns2:populationTotal \"651157\" ;\n",
      "    ns1:lat \"51.91666793823242\" ;\n",
      "    ns1:long \"4.5\" .\n",
      "\n",
      "ex:closeBy rdfs:domain ex:Location ;\n",
      "    rdfs:range ex:Location .\n",
      "\n",
      "ex:containsCity rdfs:domain ex:Country ;\n",
      "    rdfs:range ex:City ;\n",
      "    rdfs:subPropertyOf ex:contains .\n",
      "\n",
      "ex:Capital rdfs:subClassOf ex:City .\n",
      "\n",
      "ex:City rdfs:subClassOf ex:Location .\n",
      "\n",
      "ex:Country rdfs:subClassOf ex:Location .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mergedGraph = g + h\n",
    "\n",
    "save_graph(mergedGraph, 'extended-example.ttl')\n",
    "\n",
    "serialize_graph(mergedGraph)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: (25 points)  Implement Basic Inferencing Rules "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture we showed that the RDFS inference rules can be used to infer new knowledge. For example, infer class membership based on _rdfs:domain_ or infer relationships between subjects and objects based on _rdfs:subPropertyOf_. \n",
    "\n",
    "Create rules to inference class membership based on the RDF Schema language features \n",
    "*\tFor example: infer that an instance belongs to a class because of domain and range restrictions\n",
    "*\tFor example: infer that an instance belongs to a (super)class because it also belongs to a subclass\n",
    "\n",
    "We implemented the __rdfs2__ rule. You should implement the 5 following remaining rules:  \n",
    "\n",
    "*     (rdfs2) If G contains the triples (aaa rdfs:domain xxx.) and (uuu aaa yyy.)  then infer the triple (uuu rdf:type xxx.)\n",
    "*     (rdfs3) If G contains the triples (aaa rdfs:range xxx.) and (uuu aaa vvv.) then infer the triple (vvv rdf:type xxx .)\n",
    "*     (rdfs5) If G contains the triples (uuu rdfs:subPropertyOf vvv.) and (vvv rdfs:subPropertyOf xxx.) then infer the triple\n",
    "(uuu rdfs:subPropertyOf xxx.) \n",
    "*     (rdfs7) If G contains the triples (aaa rdfs:subPropertyOf bbb.) and (uuu aaa yyy.) then infer the triple (uuu bbb yyy) \n",
    "*     (rdfs9) If G contains the triples (uuu rdfs:subClassOf xxx.) and (vvv rdf:type uuu.) then infer the triple\n",
    " (vvv rdf:type xxx.)   -> this one was not mentioned in the lecture, but is a very important one. \n",
    "*     (rdfs11) If G contains the triples (uuu rdfs:subClassOf vvv.) and (vvv rdfs:subClassOf xxx.) then infer the triple\n",
    "(uuu rdfs:subClassOf xxx.)\n",
    "\n",
    "\n",
    "Run your rule reasoner on your knowledge graph. If you have implemented everything correctly, you should find exactly 17 inferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(rdfs 3)  http://example.com/kad/Amsterdam rdf:type http://example.com/kad/Capital\n",
      "(rdfs 3)  http://example.com/kad/Berlin rdf:type http://example.com/kad/Capital\n",
      "(rdfs 9)  http://example.com/kad/Germany rdf:type http://example.com/kad/Country\n",
      "(rdfs 11)  http://example.com/kad/EuropeanCountry rdfs:subClassOf http://example.com/kad/Location\n",
      "(rdfs 2)  http://example.com/kad/Amsterdam rdf:type http://example.com/kad/Location\n",
      "(rdfs 3)  http://example.com/kad/Rotterdam rdf:type http://example.com/kad/City\n",
      "(rdfs 7)  http://example.com/kad/Netherlands http://example.com/kad/closeBy http://example.com/kad/Belgium\n",
      "(rdfs 9)  http://example.com/kad/Netherlands rdf:type http://example.com/kad/Location\n",
      "(rdfs 9)  http://example.com/kad/Belgium rdf:type http://example.com/kad/Location\n",
      "(rdfs 9)  http://example.com/kad/Amsterdam rdf:type http://example.com/kad/City\n",
      "(rdfs 11)  http://example.com/kad/Capital rdfs:subClassOf http://example.com/kad/Location\n",
      "(rdfs 2)  http://example.com/kad/Netherlands rdf:type http://example.com/kad/Country\n",
      "(rdfs 3)  http://example.com/kad/Germany rdf:type http://example.com/kad/Location\n",
      "(rdfs 5)  http://example.com/kad/hasCapital rdfs:subPropertyOf http://example.com/kad/contains\n",
      "(rdfs 7)  http://example.com/kad/Netherlands http://example.com/kad/containsCity http://example.com/kad/Amsterdam\n",
      "(rdfs 7)  http://example.com/kad/Germany http://example.com/kad/containsCity http://example.com/kad/Berlin\n",
      "(rdfs 7)  http://example.com/kad/Netherlands http://example.com/kad/contains http://example.com/kad/Rotterdam\n",
      "---------------------------------\n",
      "Number of inferred triples: 17\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "def myRDFSreasoner(myGraph):\n",
    "    inferredTriples = 0\n",
    "    for sbj, prd, obj in myGraph:\n",
    "\n",
    "        # --- rdfs2 ---\n",
    "        if (prd.eq(URIRef(\"http://www.w3.org/2000/01/rdf-schema#domain\"))):\n",
    "            generator = myGraph.subject_objects(URIRef(sbj))\n",
    "            for s, o in generator:\n",
    "                inferredTriples += 1\n",
    "                print(\"(rdfs 2) \", s, \"rdf:type\", obj)\n",
    "        \n",
    "        \n",
    "        # --- rdfs3 ---\n",
    "        if (prd.eq(URIRef(\"http://www.w3.org/2000/01/rdf-schema#range\"))):\n",
    "            generator = myGraph.subject_objects(URIRef(sbj))\n",
    "            for s, o in generator:\n",
    "                inferredTriples += 1\n",
    "                print(\"(rdfs 3) \", o, \"rdf:type\", obj)\n",
    "        \n",
    "        # --- rdfs5 ---\n",
    "        if (prd.eq(URIRef(\"http://www.w3.org/2000/01/rdf-schema#subPropertyOf\"))):\n",
    "            generator = myGraph.objects(URIRef(obj), URIRef(\"http://www.w3.org/2000/01/rdf-schema#subPropertyOf\"))\n",
    "            for o in generator:\n",
    "                inferredTriples += 1\n",
    "                print(\"(rdfs 5) \", sbj, \"rdfs:subPropertyOf\", o)\n",
    "        \n",
    "        # --- rdfs7 ---\n",
    "        if (prd.eq(URIRef(\"http://www.w3.org/2000/01/rdf-schema#subPropertyOf\"))):\n",
    "            generator = myGraph.subject_objects(URIRef(sbj))\n",
    "            for s, o in generator:\n",
    "                inferredTriples += 1\n",
    "                print(\"(rdfs 7) \", s, obj, o)\n",
    "        \n",
    "        # --- rdfs9 ---\n",
    "        if (prd.eq(URIRef(\"http://www.w3.org/2000/01/rdf-schema#subClassOf\"))):\n",
    "            generator = myGraph.subjects(URIRef(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\"), URIRef(sbj))\n",
    "            for s in generator:\n",
    "                inferredTriples += 1\n",
    "                print(\"(rdfs 9) \", s, \"rdf:type\", obj)\n",
    "        \n",
    "        # --- rdfs11 ---\n",
    "        if (prd.eq(URIRef(\"http://www.w3.org/2000/01/rdf-schema#subClassOf\"))):\n",
    "            generator = myGraph.objects(URIRef(obj), URIRef(\"http://www.w3.org/2000/01/rdf-schema#subClassOf\"))\n",
    "            for o in generator:\n",
    "                inferredTriples += 1\n",
    "                print(\"(rdfs 11) \", sbj, \"rdfs:subClassOf\", o)\n",
    "\n",
    "        \n",
    "        \n",
    "    print(\"---------------------------------\")\n",
    "    print(\"Number of inferred triples:\", inferredTriples)\n",
    "    print(\"---------------------------------\")\n",
    "    \n",
    "myRDFSreasoner(g)  # test your reasoner\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: (20 points) Build your very own RDFS knowledge graph. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a small RDF Schema vocabulary in Turtle. You can choose your own domain (e.g. movies, geography, sports), as long as it hasn't been used as an example during the lectures. The following rules must be respected:\n",
    "*\tThe schema should define at least 4 classes, 4 properties, and 4 instances.\n",
    "*   The properties should be used to relate the instances (i.e., object-type relations)\n",
    "*\tThe instances should be members of at least one of the 4 defined classes\n",
    "*\tAll resources should have an rdfs:label attribute in a suitable language.\n",
    "\n",
    "You should use (at least) the following language features of RDF and RDFS:\n",
    "* \trdf:type (or 'a')\n",
    "* \trdfs:subClassOf\n",
    "* \trdfs:subPropertyOf\n",
    "* \trdfs:domain and rdfs:range\n",
    "*\trdfs:label\n",
    "\n",
    "Be sure to define the 'rdf:' and 'rdfs:' namespace prefixes for RDF and RDF Schema in your file (perhaps have a look at http://prefix.cc)\n",
    "\n",
    "For creating your vocabulary you should add the axioms directly (programatically) to your Knowledge Graph as you did last week. \n",
    "\n",
    "Play around with the inference rules you have created in the previous task to make sure that you added some implicit knowledge, that becomes \"visible\" via inferencing (this will be useful for the next task). \n",
    "\n",
    "Finally:\n",
    "- Add the knowledge you created into the RDFlib graph datastructure *myRDFSgraph*, \n",
    "- Print *myRDFSgraph* in Turtle so that we can check your \"design\"\n",
    "- Save *myRDFSgraph* into a new file 'myRDFSgraph.ttl' (it is not necessary to submit this file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now let's check what we can infer from your knowledge graph...\n",
      "The more rules you cover, the better!\n",
      "@prefix ns1: <http://example.com/kad/> .\n",
      "@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "\n",
      "ns1:Actor a rdfs:Class ;\n",
      "    rdfs:label \"Actor\" ;\n",
      "    rdfs:subClassOf ns1:Person .\n",
      "\n",
      "ns1:Cinema a rdfs:Class ;\n",
      "    rdfs:label \"Cinema\",\n",
      "        \"Pathé\" .\n",
      "\n",
      "ns1:Director a rdfs:Class ;\n",
      "    rdfs:label \"Director\" .\n",
      "\n",
      "ns1:Human a rdfs:Class ;\n",
      "    rdfs:label \"Human\" .\n",
      "\n",
      "ns1:Person a rdfs:Class ;\n",
      "    rdfs:label \"Person\" ;\n",
      "    rdfs:subClassOf ns1:Human .\n",
      "\n",
      "ns1:Cineworld a ns1:Cinema .\n",
      "\n",
      "ns1:IT a ns1:Movie ;\n",
      "    rdfs:label \"IT\" .\n",
      "\n",
      "ns1:Johnny_Depp a ns1:Actor ;\n",
      "    rdfs:label \"Johnny Depp\" .\n",
      "\n",
      "ns1:Murphy a ns1:Actor ;\n",
      "    ns1:isDirectedBy ns1:Nolan ;\n",
      "    ns1:playsIn ns1:Inception .\n",
      "\n",
      "ns1:Steven_Spielberg a ns1:Director ;\n",
      "    rdfs:label \"Steven Spielberg\" .\n",
      "\n",
      "ns1:isDirectedBy a rdf:Property ;\n",
      "    rdfs:label \"is directed by\" ;\n",
      "    rdfs:domain ns1:Actor ;\n",
      "    rdfs:range ns1:Director ;\n",
      "    rdfs:subPropertyOf ns1:directs .\n",
      "\n",
      "ns1:isShownAt a rdf:Property ;\n",
      "    rdfs:label \"is directed by\" ;\n",
      "    rdfs:domain ns1:Movie ;\n",
      "    rdfs:range ns1:Cinema .\n",
      "\n",
      "ns1:playsIn a rdf:Property ;\n",
      "    rdfs:label \"plays in\" ;\n",
      "    rdfs:domain ns1:Actor ;\n",
      "    rdfs:range ns1:Movie .\n",
      "\n",
      "ns1:Nolan a ns1:Director ;\n",
      "    ns1:directs ns1:Inception .\n",
      "\n",
      "ns1:Pathé a ns1:Cinema .\n",
      "\n",
      "ns1:directs a rdf:Property ;\n",
      "    rdfs:label \"director\" ;\n",
      "    rdfs:domain ns1:Director ;\n",
      "    rdfs:range ns1:Movie .\n",
      "\n",
      "ns1:Inception a ns1:Movie ;\n",
      "    ns1:isShownAt ns1:Pathé .\n",
      "\n",
      "ns1:Movie a ns1:Class ;\n",
      "    rdfs:label \"Movie\" .\n",
      "\n",
      "\n",
      "(rdfs 9)  http://example.com/kad/Johnny_Depp rdf:type http://example.com/kad/Person\n",
      "(rdfs 9)  http://example.com/kad/Murphy rdf:type http://example.com/kad/Person\n",
      "(rdfs 11)  http://example.com/kad/Actor rdfs:subClassOf http://example.com/kad/Human\n",
      "(rdfs 3)  http://example.com/kad/Inception rdf:type http://example.com/kad/Movie\n",
      "(rdfs 3)  http://example.com/kad/Pathé rdf:type http://example.com/kad/Cinema\n",
      "(rdfs 3)  http://example.com/kad/Nolan rdf:type http://example.com/kad/Director\n",
      "(rdfs 2)  http://example.com/kad/Murphy rdf:type http://example.com/kad/Actor\n",
      "(rdfs 3)  http://example.com/kad/Inception rdf:type http://example.com/kad/Movie\n",
      "(rdfs 2)  http://example.com/kad/Murphy rdf:type http://example.com/kad/Actor\n",
      "(rdfs 2)  http://example.com/kad/Nolan rdf:type http://example.com/kad/Director\n",
      "(rdfs 2)  http://example.com/kad/Inception rdf:type http://example.com/kad/Movie\n",
      "(rdfs 7)  http://example.com/kad/Murphy http://example.com/kad/directs http://example.com/kad/Nolan\n",
      "---------------------------------\n",
      "Number of inferred triples: 12\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "myRDFSgraph = Graph()\n",
    "\n",
    "ex = Namespace(\"http://example.com/kad/\")\n",
    "rdf = Namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "rdfs = Namespace(\"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "\n",
    "myRDFSgraph.add((ex.Person, rdf.type, rdfs.Class))\n",
    "myRDFSgraph.add((ex.Person, rdfs.label, Literal(\"Person\")))\n",
    "\n",
    "myRDFSgraph.add((ex.Movie, rdf.type, ex.Class))\n",
    "myRDFSgraph.add((ex.Movie, rdfs.label, Literal(\"Movie\")))\n",
    "\n",
    "myRDFSgraph.add((ex.Actor, rdf.type, rdfs.Class))\n",
    "myRDFSgraph.add((ex.Actor, rdfs.label, Literal(\"Actor\")))\n",
    "myRDFSgraph.add((ex.Actor, rdfs.subClassOf, ex.Person))\n",
    "\n",
    "myRDFSgraph.add((ex.Director, rdf.type, rdfs.Class))\n",
    "myRDFSgraph.add((ex.Director, rdfs.label, Literal(\"Director\")))\n",
    "myRDFSgraph.add((ex.Actor, rdfs.subClassOf, ex.Person))\n",
    "\n",
    "myRDFSgraph.add((ex.Cinema, rdf.type, rdfs.Class))\n",
    "myRDFSgraph.add((ex.Cinema, rdfs.label, Literal(\"Cinema\")))\n",
    "\n",
    "\n",
    "myRDFSgraph.add((ex.playsIn, rdf.type, rdf.Property))\n",
    "myRDFSgraph.add((ex.playsIn, rdfs.domain, ex.Actor))\n",
    "myRDFSgraph.add((ex.playsIn, rdfs.range, ex.Movie))\n",
    "myRDFSgraph.add((ex.playsIn, rdfs.label, Literal(\"plays in\")))\n",
    "\n",
    "myRDFSgraph.add((ex.directs, rdf.type, rdf.Property))\n",
    "myRDFSgraph.add((ex.directs, rdfs.domain, ex.Director))\n",
    "myRDFSgraph.add((ex.directs, rdfs.range, ex.Movie))\n",
    "myRDFSgraph.add((ex.directs, rdfs.label, Literal(\"director\")))\n",
    "\n",
    "myRDFSgraph.add((ex.isDirectedBy, rdf.type, rdf.Property))\n",
    "myRDFSgraph.add((ex.isDirectedBy, rdfs.domain, ex.Actor))\n",
    "myRDFSgraph.add((ex.isDirectedBy, rdfs.subPropertyOf, ex.directs))\n",
    "myRDFSgraph.add((ex.isDirectedBy, rdfs.range, ex.Director))\n",
    "myRDFSgraph.add((ex.isDirectedBy, rdfs.label, Literal(\"is directed by\")))\n",
    "\n",
    "myRDFSgraph.add((ex.isShownAt, rdf.type, rdf.Property))\n",
    "myRDFSgraph.add((ex.isShownAt, rdfs.domain, ex.Movie))\n",
    "myRDFSgraph.add((ex.isShownAt, rdfs.range, ex.Cinema))\n",
    "myRDFSgraph.add((ex.isShownAt, rdfs.label, Literal(\"is directed by\")))\n",
    "\n",
    "myRDFSgraph.add((ex.Johnny_Depp, rdf.type, ex.Actor))\n",
    "myRDFSgraph.add((ex.Johnny_Depp, rdfs.label, Literal(\"Johnny Depp\")))\n",
    "\n",
    "\n",
    "myRDFSgraph.add((ex.Murphy, rdf.type, ex.Actor))\n",
    "myRDFSgraph.add((ex.Murphy, ex.playsIn, ex.Inception))\n",
    "\n",
    "myRDFSgraph.add((ex.IT, rdf.type, ex.Movie))\n",
    "myRDFSgraph.add((ex.IT, rdfs.label, Literal(\"IT\")))\n",
    "\n",
    "myRDFSgraph.add((ex.Inception, rdf.type, ex.Movie))\n",
    "\n",
    "myRDFSgraph.add((ex.Steven_Spielberg, rdf.type, ex.Director))\n",
    "myRDFSgraph.add((ex.Steven_Spielberg, rdfs.label, Literal(\"Steven Spielberg\")))\n",
    "\n",
    "myRDFSgraph.add((ex.Nolan, rdf.type, ex.Director))\n",
    "myRDFSgraph.add((ex.Nolan, ex.directs, ex.Inception))\n",
    "myRDFSgraph.add((ex.Murphy, ex.isDirectedBy, ex.Nolan))\n",
    "\n",
    "myRDFSgraph.add((ex.Pathé, rdf.type, ex.Cinema))\n",
    "myRDFSgraph.add((ex.Cinema, rdfs.label, Literal(\"Pathé\")))\n",
    "myRDFSgraph.add((ex.Inception, ex.isShownAt, ex.Pathé))\n",
    "\n",
    "myRDFSgraph.add((ex.Cineworld, rdf.type, ex.Cinema))\n",
    "\n",
    "myRDFSgraph.add((ex.Person, rdfs.subClassOf, ex.Human))  \n",
    "myRDFSgraph.add((ex.Human, rdf.type, rdfs.Class))\n",
    "myRDFSgraph.add((ex.Human, rdfs.label, Literal(\"Human\")))\n",
    "\n",
    "myRDFSgraph.add((ex.Person, rdfs.subClassOf, ex.Human))  \n",
    "myRDFSgraph.add((ex.Human, rdf.type, rdfs.Class))\n",
    "myRDFSgraph.add((ex.Human, rdfs.label, Literal(\"Human\")))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Now let's check what we can infer from your knowledge graph...\")\n",
    "print(\"The more rules you cover, the better!\")\n",
    "\n",
    "save_graph(myRDFSgraph, 'myRDFSgraph.ttl')\n",
    "serialize_graph(myRDFSgraph)\n",
    "\n",
    "myRDFSreasoner(myRDFSgraph)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 (20 points) Compare local inferences with GraphDB results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload *myRDFSgraph.ttl* to GraphDB (check [the GraphDB tutorial](https://github.com/ucds-vu/knowledge-data-vu/blob/master/Tutorials/Preliminaries/tutorial-GraphDB.md) before starting to work with GraphDB).\n",
    "\n",
    "Formulate two different SPARQL queries, and write a Python code that executes these queries over your GraphDB SPARQL endpoint (check example of Task 1).\n",
    "\n",
    "**Each SPARQL query should return a _different type_ of inferred knowledge** (at least one triple that was not explicitly asserted in the graph).\n",
    "\n",
    "Specify below next to your query (using a comment '# ...') which type of RDFS rule is the GraphDB reasoner using to infer this answer (rdfs2, rdfs3, rdfs5, rdfs7, rdfs9, rdfs11). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your GraphDB repository URL (setup -> repositories -> repository url) and assign it to the variable 'myEndpoint' below. \n",
    "# It should be similar to this: \n",
    "\n",
    "myEndpoint = \"http://127.0.0.1:7200/repositories/KnowledgeAndData\"  # KnowledgeAndData is the name of the repository\n",
    "sparql = SPARQLWrapper(myEndpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 1 - Specify which RDFS rule are you testing: \n",
    "\n",
    "# Check example of Task 1 on how to query remote SPARQL endpoints\n",
    "\n",
    "sparql.setQuery(\"\"\"\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 2 - Specify which RDFS rule are you testing: \n",
    "\n",
    "# Check example of Task 1 on how to query remote SPARQL endpoints\n",
    "\n",
    "sparql.setQuery(\"\"\"\n",
    "\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting the assignment\n",
    "\n",
    "Please submit this notebook (.ipynb) once you're finished with the assignment. It is not necessary to submit the created turtle files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
